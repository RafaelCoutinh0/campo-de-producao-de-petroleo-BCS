# -*- coding: utf-8 -*-
"""RNA_global

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dfFRua5xT_5PQqL4WxXYPPnwD7XFoOGX
"""
import optuna
#%% importações do código


import torch
import numpy as np
import torch.nn as nn
from matplotlib.style.core import library
from torch.utils.data import Dataset, DataLoader
import torch.distributions.uniform as urand
import pickle


def load_data_from_pkl(file_path):
    with open(file_path, 'rb') as file:
        data = pickle.load(file)
    return data

class MyLibraryDataset(Dataset):
    def __init__(self, library_data, feature_vars, label_vars, transform=None):
        self.library_data = library_data
        self.feature_vars = feature_vars  # Variáveis de entrada
        self.label_vars = label_vars  # Variáveis de saída (inclui a flag)
        self.flag_index = label_vars.index('flag')  # Índice da flag
        self.num_simulations = len(library_data[feature_vars[0]])
        self.transform = transform

        # Calcular limites de normalização
        self.feature_min = {var: min(library_data[var]) for var in feature_vars}
        self.feature_max = {var: max(library_data[var]) for var in feature_vars}
        self.label_min = {var: min(library_data[var]) for var in label_vars if var != 'flag'}
        self.label_max = {var: max(library_data[var]) for var in label_vars if var != 'flag'}

    def normalize(self, value, min_val, max_val):
        return 2 * (value - min_val) / (max_val - min_val) - 1  # Normalizar para o intervalo [-1, 1]

    def denormalize(self, value, min_val, max_val):
        return (value + 1) * (max_val - min_val) / 2 + min_val # Reverter do intervalo [-1, 1] para o intervalo original


    def __getitem__(self, idx):
        features = [
            self.normalize(self.library_data[var][idx], self.feature_min[var], self.feature_max[var])
            for var in self.feature_vars # Normalizar features
        ]

        labels = [
            self.library_data[var][idx] if var == 'flag' else
            self.normalize(self.library_data[var][idx], self.label_min[var], self.label_max[var])
            for var in self.label_vars # Normalizar labels, exceto a flag
        ]

        # Aplicar transformações, se houver
        if self.transform:
            features = self.transform(features)

        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float32)

    def __len__(self):
        return self.num_simulations

def weighted_mse_loss(y_pred, y_true, weights):
    """
    Calcula o MSE ponderado para cada variável de saída.

    Args:
        y_pred (Tensor): Predições do modelo.
        y_true (Tensor): Valores reais (ground truth).
        weights (Tensor): Tensor 1D contendo os pesos para cada saída.

    Returns:
        Tensor: Valor escalar da perda ponderada.
    """
    mse = (y_pred - y_true) ** 2  # MSE padrão
    weighted_mse = weights * mse  # Aplicar pesos
    return weighted_mse.mean()  # Média da perda ponderada


# Definir a rede neural
class RasmusNetwork(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()
        layers = []  # Lista temporária para criar o Sequential
        hidden_dim = 150  # Hiperparâmetro encontrado
        num_layers = 2    # Hiperparâmetro encontrado
        dropout = 8.55353740037329e-05   # Hiperparâmetro encontrado

        # Criar camadas ocultas
        for _ in range(num_layers):
            layers.append(nn.Linear(input_dim if not layers else hidden_dim, hidden_dim))
            layers.append(nn.Dropout(dropout))
            layers.append(nn.Tanh())  # Função de ativação
            layers.append(nn.Dropout(dropout))
            layers.append(nn.Tanh())  # Função de ativação


        # Camada de saída
        layers.append(nn.Linear(hidden_dim, output_dim))

        # Definir como um módulo Sequential
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        output = self.model(x)
        # Aplicar Sigmoid apenas à saída da flag (última unidade)
        output[:, -1] = torch.sigmoid(output[:, -1])
        return output


    # Treinamento
def train(model, dataloader, optimizer):
    model.train()
    cumloss = 0.0
    bce_loss_func = nn.BCEWithLogitsLoss()  # Para a flag
    output_weights = torch.tensor(
        [1.0, 1.0, 1.0, 1.0, 1,
         1.0, 1.0, 1.0, 1.0,
         1.0, 1.0, 1.0, 1.0, 1.0,
         1.0, 1.0, 1.0, 1.0, 1.0,
         1.0, 1.0, 1.0, 5.0], device=device)
    for X, y in dataloader:
        X = X.to(device)
        y = y.to(device)

        y_labels = y[:, :-1]  # Saídas contínuas
        y_flag = y[:, -1]     # Flag binária

        pred = model(X)
        pred_labels = pred[:, :-1]
        pred_flag = pred[:, -1]

        # Perda para as saídas contínuas
        loss_continuous = weighted_mse_loss(pred_labels, y_labels, output_weights[:-1])

        # Perda para a flag (binária)
        loss_flag = bce_loss_func(pred_flag, y_flag)

        # Combinar as perdas
        total_loss = loss_continuous + loss_flag

        # Backpropagation
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()

        # Acumular a perda
        cumloss += total_loss.item()
        y_labels_denorm = torch.stack([
            dataset.denormalize(y_labels[:, i], dataset.label_min[var], dataset.label_max[var])
            for i, var in enumerate(dataset.label_vars[:-1])  # Ignora a flag
        ], dim=1)
        pred_labels_denorm = torch.stack([
            dataset.denormalize(pred_labels[:, i], dataset.label_min[var], dataset.label_max[var])
            for i, var in enumerate(dataset.label_vars[:-1])  # Ignora a flag
        ], dim=1)
        y_labels_list = []
        pred_labels_list = []
        y_flag_list = []
        pred_flag_list = []
        y_labels_list.append(y_labels_denorm)
        pred_labels_list.append(pred_labels_denorm)
        y_flag_list.append(y_flag)
        pred_flag_list.append(pred_flag)

    y_labels_all = torch.cat(y_labels_list, dim=0)
    pred_labels_all = torch.cat(pred_labels_list, dim=0)
    y_flag_all = torch.cat(y_flag_list, dim=0)
    pred_flag_all = torch.cat(pred_flag_list, dim=0)
    avg_loss = cumloss / len(dataloader)
    return avg_loss, y_labels_all, pred_labels_all, y_flag_all, pred_flag_all


if __name__ == "__main__":
    file_path = 'rna_training.pkl'
    library_data = load_data_from_pkl(file_path)

    # Variáveis selecionadas
    feature_vars = [
        'p_topo', 'valve1', 'valve2', 'valve3', 'valve4',
        'bcs1_freq', 'bcs2_freq', 'bcs3_freq', 'bcs4_freq',
        'booster_freq',
    ]
    label_vars = ['q_main1', 'q_main2', 'q_main3', 'q_main4', 'q_tr',
        'P_man', 'P_fbhp1', 'P_fbhp2',
        'P_fbhp3', 'P_fbhp4', 'P_choke1', 'P_choke2',
        'P_choke3', 'P_choke4', 'P_intake1', 'P_intake2',
        'P_intake3', 'P_intake4', 'dP_bcs1', 'dP_bcs2',
        'dP_bcs3', 'dP_bcs4', 'flag']

    for var in feature_vars + label_vars:
        if var not in library_data:
            raise ValueError(f"A variável {var} não está presente no dataset!")

    # Criar o dataset e DataLoader
    input_dim = len(feature_vars)  # Dimensão da entrada
    output_dim = len(label_vars)  # Dimensão da saída
    dataset = MyLibraryDataset(library_data, feature_vars, label_vars)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Rodando na {device}")

    # Criar o modelo
    model = RasmusNetwork(input_dim=len(feature_vars), output_dim=len(label_vars)).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=2.243656143480994e-05)  # Taxa de aprendizado encontrada
    lossfunc = nn.MSELoss()

"""TREINAMENTO EM SI"""

saidas =  ['q_main1', 'q_main2', 'q_main3', 'q_main4', 'q_tr',
        'P_man', 'P_fbhp1', 'P_fbhp2',
        'P_fbhp3', 'P_fbhp4', 'P_choke1', 'P_choke2',
        'P_choke3', 'P_choke4', 'P_intake1', 'P_intake2',
        'P_intake3', 'P_intake4', 'dP_bcs1', 'dP_bcs2',
        'dP_bcs3', 'dP_bcs4']

#%%
from colorama import Fore, Style

epochs = 301  # Número de épocas
for epoch in range(epochs):
    train_loss, y_labels, pred_labels, y_flag, pred_flag = train(model, dataloader, optimizer)
    y_labels = y_labels.tolist()
    pred_labels = pred_labels.tolist()
    y_flag = y_flag.tolist()
    pred_flag = pred_flag.tolist()

    if epoch % 10 == 0:
        print(f"Epoch {epoch}: Train Loss = {train_loss}")
        print("Comparação entre modelo e RNA:")

        for i, name in enumerate(saidas):
            # Calcular a diferença percentual
            percent = abs(abs(abs(y_labels[-1][i]) - abs(pred_labels[-1][i])) / abs(y_labels[-1][i])) * 100
            # Imprimir a diferença em vermelho se houver uma discrepância significativa
            if percent > 1:  # Exemplo: se a diferença for maior que 5%, mostra em vermelho
                print(
                    f"{name}: modelo = {y_labels[-1][i]}, RNA = {pred_labels[-1][i]}, {Fore.RED}{percent:.2f}%{Style.RESET_ALL}")
            else:
                print(f"{name}: modelo = {y_labels[-1][i]}, RNA = {pred_labels[-1][i]}, {percent:.2f}%")

        # Calcular e imprimir a diferença para o flag
        percent = abs(abs(abs(y_labels[-1][-1]) - abs(pred_labels[-1][-1])) / abs(y_labels[-1][-1])) * 100
        if percent > 50:
            if y_flag[-1] < 0.5:# Exemplo: se a diferença for maior que 5%, mostra em vermelho
                print(f"Flag: modelo = {y_flag[-1]}, RNA = 0.0, {Fore.RED}{percent:.2f}%{Style.RESET_ALL}\n")
            else:
                print(f"Flag: modelo = {y_flag[-1]}, RNA = 1.0, {Fore.RED}{percent:.2f}%{Style.RESET_ALL}\n")
        else:
            if y_flag[-1] > 0.5:
                print(f"Flag: modelo = {y_flag[-1]}, RNA = 1.0, {percent:.2f}%\n")
            else:
                print(f"Flag: modelo = {y_flag[-1]}, RNA = 0.0, {percent:.2f}%\n")


#
# import optuna
#
# # Função objetivo para o Optuna
# def objective(trial):
#     # Hiperparâmetros a serem otimizados
#     lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)
#     hidden_dim = trial.suggest_int('hidden_dim', 16, 150)
#     num_layers = trial.suggest_int('num_layers', 1, 5)
#     dropout = trial.suggest_float('dropout', 0.0, 0.5)
#
#     # Criar o modelo dinâmico com os hiperparâmetros
#     class RasmusNetwork(nn.Module):
#         def __init__(self, input_dim, output_dim):
#             super().__init__()
#             layers = []
#             for _ in range(num_layers):
#                 layers.append(nn.Linear(input_dim if not layers else hidden_dim, hidden_dim))
#                 layers.append(nn.Dropout(dropout))
#                 layers.append(nn.Tanh())  # Função de ativação
#                 layers.append(nn.Dropout(dropout))
#                 layers.append(nn.Tanh())  # Função de ativação
#             layers.append(nn.Linear(hidden_dim, output_dim))
#             self.model = nn.Sequential(*layers)
#
#         def forward(self, x):
#             output = self.model(x)
#             output[:, -1] = torch.sigmoid(output[:, -1])
#             return output
#
#     # Criar o modelo
#     model = RasmusNetwork(input_dim=len(feature_vars), output_dim=len(label_vars)).to(device)
#
#     # Configurar o otimizador e função de perda
#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)
#
#     # Treinamento
#     epochs = 10  # Número de épocas fixo
#     for epoch in range(epochs):
#         train_loss, y_labels, pred_labels, y_flag, pred_flag = train(model, dataloader, optimizer)
#
#     # Retornar a perda final para o Optuna
#     return train_loss
#
# # Configurar e executar o estudo
# study = optuna.create_study(direction='minimize')  # Minimizar a perda
# study.optimize(objective, n_trials=20)  # Número de execuções
#
# # Exibir os melhores hiperparâmetros encontrados
# print("Melhores hiperparâmetros:", study.best_params)

